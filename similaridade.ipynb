{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c74164dd",
   "metadata": {},
   "source": [
    "Identificação dos itens existentes no catálogo (arquivo items_titles.csv) mais similares aos novos itens (arquivo items_titles_test.csv)\n",
    "\n",
    "Abordagem utilizada: \n",
    "Clusterizar cada item no catálogo. O cálculo da similaridade é realizado apenas com os itens do catálogo que pertencem ao mesmo cluster "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264cef8c",
   "metadata": {},
   "source": [
    "#### Funções de preparação dos dados  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d28a0976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover_palavras(data , lista_remocao , coluna_texto , nova_coluna_texto ): #Remover stopwords\n",
    "   \n",
    "    token_espaco = tokenize.WordPunctTokenizer()\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        frase = list()\n",
    "        for palavra in token_espaco.tokenize(row[coluna_texto]):\n",
    "            if palavra not in lista_remocao:\n",
    "                frase.append(palavra)\n",
    "        data.at[i , nova_coluna_texto ] = ' '.join(frase)\n",
    "        \n",
    "def ajustes_diversos_dominio(data , coluna_texto , nova_coluna_texto , tamanho_minimo ): #Remover stopwords\n",
    "    import re\n",
    "    token_espaco = tokenize.WordPunctTokenizer()\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        frase = list()\n",
    "        for palavra in token_espaco.tokenize(row[coluna_texto]):\n",
    "            palavra = re.sub(r\"[!\\\"'#$%&()*+,-\\.\\/:;<=>?@[\\\\\\]^_`{|}~]\", ' ', palavra)\n",
    "            if(palavra == 'tv'):\n",
    "                frase.append('televisao')\n",
    "            else:\n",
    "                if len(palavra) > tamanho_minimo:\n",
    "                    frase.append(palavra)\n",
    "        data.at[i , nova_coluna_texto ] = ' '.join(frase)\n",
    "                \n",
    "        \n",
    "# =============================================================================\n",
    "# Aplica as tranformações necessárias para normalizar o texto da coluna text_col do DataFrame df\n",
    "# Retorna um novo DF com uma coluna adicional com o nome de text_col + '_transf'\n",
    "# =============================================================================\n",
    "def preparar_dados(df , text_col):\n",
    "    df_transf = pd.DataFrame()\n",
    "    df_transf[text_col] = df[text_col]\n",
    "    \n",
    "    df_transf['trat1_lowercase'] = [unidecode.unidecode(texto.lower()) for texto in df_transf[text_col]]\n",
    "    ajustes_diversos_dominio(df_transf , \"trat1_lowercase\" , \"trat2_diversos\" , tamanho_minimo=2 )\n",
    "    \n",
    "    palavras_irrelevantes = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "    remover_palavras(df_transf , palavras_irrelevantes ,  \"trat2_diversos\" , \"trat3_sem_sw\" )\n",
    "\n",
    "    #removendo linha inválida no dataset\n",
    "    df_transf = df_transf.loc[df_transf['trat3_sem_sw'] != '']\n",
    "\n",
    "    lemm = nltk.stem.RSLPStemmer()\n",
    "    df_transf[text_col + '_transf'] = [lemm.stem(palavra) for palavra in df_transf['trat3_sem_sw']]\n",
    "    \n",
    "    return df_transf.drop( ['trat1_lowercase' , 'trat2_diversos' , 'trat3_sem_sw' ] , axis = 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265a3162",
   "metadata": {},
   "source": [
    "Leitura dos itens do catálogo e preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59ff8b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ulf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "import unidecode\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from time import time\n",
    "\n",
    "avaliacao_performance = pd.DataFrame(columns=['Descricao' , 'Tempo'] , index=[0])\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "df_base = pd.read_csv(\"items_titles.csv\")\n",
    "df_base = preparar_dados(df_base , 'ITE_ITEM_TITLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a62c74b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITE_ITEM_TITLE</th>\n",
       "      <th>ITE_ITEM_TITLE_transf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tênis Ascension Posh Masculino - Preto E Verme...</td>\n",
       "      <td>tenis ascension posh masculino preto vermelh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tenis Para Caminhada Super Levinho Spider Corr...</td>\n",
       "      <td>tenis caminhada super levinho spider corr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tênis Feminino Le Parc Hocks Black/ice Origina...</td>\n",
       "      <td>tenis feminino parc hocks black ice original envi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tênis Olympikus Esportivo Academia Nova Tendên...</td>\n",
       "      <td>tenis olympikus esportivo academia nova tenden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Inteligente Led Bicicleta Tauda Luz Usb Bicicl...</td>\n",
       "      <td>inteligente led bicicleta tauda luz usb bicicl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      ITE_ITEM_TITLE  \\\n",
       "0  Tênis Ascension Posh Masculino - Preto E Verme...   \n",
       "1  Tenis Para Caminhada Super Levinho Spider Corr...   \n",
       "2  Tênis Feminino Le Parc Hocks Black/ice Origina...   \n",
       "3  Tênis Olympikus Esportivo Academia Nova Tendên...   \n",
       "4  Inteligente Led Bicicleta Tauda Luz Usb Bicicl...   \n",
       "\n",
       "                               ITE_ITEM_TITLE_transf  \n",
       "0       tenis ascension posh masculino preto vermelh  \n",
       "1          tenis caminhada super levinho spider corr  \n",
       "2  tenis feminino parc hocks black ice original envi  \n",
       "3  tenis olympikus esportivo academia nova tenden...  \n",
       "4  inteligente led bicicleta tauda luz usb bicicl...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c2d6ef",
   "metadata": {},
   "source": [
    "Criaçao dos modelos de vetorização e clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d817c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 29999, n_features: 16245\n"
     ]
    }
   ],
   "source": [
    "tempo_inicial = time()\n",
    "\n",
    "vectorizer = TfidfVectorizer( \n",
    "\n",
    ")\n",
    "\n",
    "matriz_vetorizada_esparsa = vectorizer.fit_transform(df_base['ITE_ITEM_TITLE_transf'])\n",
    "\n",
    "new_row = pd.DataFrame( {'Descricao':'Criacao do Vetorizador', 'Tempo': (time() - tempo_inicial) } , index=[0])\n",
    "avaliacao_performance = pd.concat([ avaliacao_performance , new_row] , ignore_index=True )\n",
    "\n",
    "print(f\"n_samples: {matriz_vetorizada_esparsa.shape[0]}, n_features: {matriz_vetorizada_esparsa.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e74eaaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de itens nulos: 0\n"
     ]
    }
   ],
   "source": [
    "# Testes do resultado da vetorizacao. Erros quando não vetorizou nenhuma palavra\n",
    "aux_teste = vectorizer.inverse_transform(matriz_vetorizada_esparsa)\n",
    "aux_somatorio = matriz_vetorizada_esparsa.sum(axis = 1)\n",
    "\n",
    "count = 0\n",
    "for idx, x in enumerate(aux_somatorio):\n",
    "    if x == 0:\n",
    "        count = count + 1\n",
    "        print(f'ORIGINAL: {df_base.loc[idx][0]}  PREPARADO: {df_base.loc[idx][1]}   VETORIZADO:{aux_teste[idx]}')\n",
    "print(f'Total de itens nulos: {count}')\n",
    "\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0575bf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de elementos de cada cluster: [  36   95  335  105   86  165  101  136   27   51   47   21  372   28\n",
      "   74   96  284  111  109   72   74  128   64  139   59   52  113   70\n",
      "   54   64  114   99   90  131   26   31   15   55   27   23   93   76\n",
      "  353   50   94   74  128  134   97   17   23   68   69   11  180   48\n",
      "   26   13  104   79  347  105   96   64  229  149  120  166  141   46\n",
      "   82  126  223  151   26  107   12   29   60  101    2   65   47   82\n",
      "  193   57   48   65  487  162   68   31  206  212  158   53  141  162\n",
      "  177   54  116   65  104  247   70   82  120   29  111  152  122  158\n",
      "   56   58  222   58   59   94   13  175   38   65   15  146   49   20\n",
      "   99   26   99   82  289  195  192  150  202   38   44   74   89  149\n",
      "   23   26  133   29  173   92  255   66   34   95   99   75   24   57\n",
      " 1481   73   60   59   24  164   59   43  113   33   17   31   68   60\n",
      "  218   50   43   25   48   78   92   60   35   96  247  156   64   68\n",
      "  104  142   42  124   45   34  194   18  134  167  153  135   38  160\n",
      "   29  119   87   64  251   75   22   38   56  282   43   44   47   28\n",
      "  144   55   54   57   75   34   34   46   37   96  223  230   97   38\n",
      "   67   44  160  150   50   31   91  111   31   31  304  268   33   21\n",
      "   18   59   53   65   36   34  573  173   46   73   36   53   33   45\n",
      "  132  118   72   40   54   38   74  428   23  148   79   23  110   69\n",
      "  173   39  108   98  105   51   91  126  105   89  182   55  100  119\n",
      "   25   59   75   31   12  179   17   63   65  103   67   43   30  137\n",
      "   46   47   42  159   57   25]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "tempo_inicial = time()\n",
    "\n",
    "clusterizador = KMeans(\n",
    "    n_clusters=300,\n",
    "    max_iter=100,\n",
    "    n_init=5,\n",
    ").fit(matriz_vetorizada_esparsa)\n",
    "\n",
    "\n",
    "new_row = pd.DataFrame( {'Descricao':'Criação do Clusterizador', 'Tempo': (time() - tempo_inicial) } , index=[0])\n",
    "avaliacao_performance = pd.concat([ avaliacao_performance , new_row] , ignore_index=True )\n",
    "\n",
    "cluster_ids, cluster_sizes = np.unique(clusterizador.labels_, return_counts=True)\n",
    "print(f\"Numero de elementos de cada cluster: {cluster_sizes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82a296a",
   "metadata": {},
   "source": [
    "#### Criaçao do dicionario key: cluster  value: list com os indices das linhas que foram classificadas neste clus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fc2fdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "dicti_clusters = defaultdict(list)\n",
    "\n",
    "an_index = 0\n",
    "for i in clusterizador.labels_:\n",
    "    dicti_clusters[i].append(an_index)\n",
    "    an_index = an_index+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93b8754",
   "metadata": {},
   "source": [
    "### Leitura e preparação dos dados da solução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "161e7288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITE_ITEM_TITLE</th>\n",
       "      <th>ITE_ITEM_TITLE_transf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>Tênis Fila Classic Runner Marinho E Vermelho</td>\n",
       "      <td>tenis fila classic runner marinho vermelh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8268</th>\n",
       "      <td>Tênis Destroyer Goyazes Ferradura Bronze</td>\n",
       "      <td>tenis destroyer goyazes ferradura bronz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4417</th>\n",
       "      <td>Tênis Calce Fácil Masculino Preto Tenis Slip O...</td>\n",
       "      <td>tenis calce facil masculino preto tenis slip b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3300</th>\n",
       "      <td>Tênis Jogger Euroflex Masculino Couro Cadarço ...</td>\n",
       "      <td>tenis jogger euroflex masculino couro cadarco ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303</th>\n",
       "      <td>Tela E Barras De Led Tv Semp 40l2400 Não Envio...</td>\n",
       "      <td>tela barras led televisao semp 40l2400 nao env...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ITE_ITEM_TITLE  \\\n",
       "467        Tênis Fila Classic Runner Marinho E Vermelho   \n",
       "8268           Tênis Destroyer Goyazes Ferradura Bronze   \n",
       "4417  Tênis Calce Fácil Masculino Preto Tenis Slip O...   \n",
       "3300  Tênis Jogger Euroflex Masculino Couro Cadarço ...   \n",
       "2303  Tela E Barras De Led Tv Semp 40l2400 Não Envio...   \n",
       "\n",
       "                                  ITE_ITEM_TITLE_transf  \n",
       "467           tenis fila classic runner marinho vermelh  \n",
       "8268            tenis destroyer goyazes ferradura bronz  \n",
       "4417  tenis calce facil masculino preto tenis slip b...  \n",
       "3300  tenis jogger euroflex masculino couro cadarco ...  \n",
       "2303  tela barras led televisao semp 40l2400 nao env...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "df_base_test = pd.read_csv(\"items_titles_test.csv\")\n",
    "\n",
    "#Definir sample para testes\n",
    "df_base_test = df_base_test.sample(n=100)\n",
    "\n",
    "df_base_test = preparar_dados(df_base_test , 'ITE_ITEM_TITLE')\n",
    "\n",
    "matriz_vetorizada_esparsa_test = vectorizer.transform(df_base_test['ITE_ITEM_TITLE_transf'])\n",
    "\n",
    "df_base_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e62fc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de itens nulos na vetorizaçao: 0\n"
     ]
    }
   ],
   "source": [
    "# Testes do resultado da vetorizacao. Erros quando não vetorizou nenhuma palavra\n",
    "aux_teste = vectorizer.inverse_transform(matriz_vetorizada_esparsa_test)\n",
    "aux_somatorio = matriz_vetorizada_esparsa_test.sum(axis = 1)\n",
    "\n",
    "count = 0\n",
    "for idx, x in enumerate(aux_somatorio):\n",
    "    if x == 0:\n",
    "        count = count + 1\n",
    "        print(f'ORIGINAL: {df_base_test.loc[idx][0]}  PREPARADO: {df_base_test.loc[idx][1]}   VETORIZADO:{aux_teste[idx]}')\n",
    "print(f'Total de itens nulos na vetorizaçao: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd96811",
   "metadata": {},
   "source": [
    "### Obtenção dos itens mais similares do catalogo para cada novo item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9548e134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informações sobre o tempo de execução das predições\n",
      "count    100.000000\n",
      "mean       0.057558\n",
      "std        0.008175\n",
      "min        0.040602\n",
      "25%        0.050193\n",
      "50%        0.057343\n",
      "75%        0.063167\n",
      "max        0.080218\n",
      "Name: Tempo, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "final_result = pd.DataFrame()\n",
    "numero_resultados = 3\n",
    "\n",
    "avaliacao_performance_predicao = pd.DataFrame(columns=['Descricao' , 'Tempo'] , index=[0])\n",
    "\n",
    "tempo_inicial = time()\n",
    "\n",
    "for an_index , an_item in enumerate(matriz_vetorizada_esparsa_test):\n",
    "    tempo_inicial_iteracao = time()\n",
    "    \n",
    "    item_procurado_str = df_base_test.iloc[an_index]['ITE_ITEM_TITLE']\n",
    "    # item = matriz_vetorizada_esparsa_test[100]\n",
    "    \n",
    "    cluster_item_procurado = clusterizador.predict(an_item)[0]\n",
    "    \n",
    "    indices_cluster_procurado = np.array(dicti_clusters[cluster_item_procurado])\n",
    "    \n",
    "    itens_no_cluster_procurado = df_base.iloc[indices_cluster_procurado]\n",
    "    \n",
    "    #preciso pegar os itens do cluster na base original\n",
    "    matriz_cluster_catalogo = matriz_vetorizada_esparsa[indices_cluster_procurado,:]\n",
    "    \n",
    "    matriz_similaridade = cosine_similarity(matriz_cluster_catalogo , an_item )\n",
    "    \n",
    "    result = pd.DataFrame()\n",
    "   \n",
    "    result['ITE_ITEM_TITLE_CATALOGO'] = itens_no_cluster_procurado['ITE_ITEM_TITLE']\n",
    "    result.reset_index(inplace=True)\n",
    "    aux = pd.DataFrame(matriz_similaridade , columns=['SIMILARIDADE'])\n",
    "    result['SIMILARIDADE'] = aux['SIMILARIDADE']\n",
    "    \n",
    "    aux = result.sort_values(by=['SIMILARIDADE'] , ascending = False)\n",
    "    \n",
    "    aux1=aux.iloc[0:numero_resultados]\n",
    "    aux1 = aux1.reset_index()\n",
    "    aux_series =  pd.Series([item_procurado_str for x in range(numero_resultados)])\n",
    "    aux1['ITE_ITEM_TITLE_PROCURADO'] = aux_series\n",
    "    \n",
    "    final_result = pd.concat( [final_result , aux1] , ignore_index=True)\n",
    "    \n",
    "    new_row = pd.DataFrame( {'Descricao': f'Execução da predição {an_index}', 'Tempo': (time() - tempo_inicial_iteracao) } , index=[0])\n",
    "    avaliacao_performance_predicao = pd.concat([ avaliacao_performance_predicao , new_row] , ignore_index=True )\n",
    "\n",
    "new_row = pd.DataFrame( {'Descricao':'Execução Total da predição', 'Tempo': (time() - tempo_inicial) } , index=[0])\n",
    "avaliacao_performance = pd.concat([ avaliacao_performance , new_row] , ignore_index=True )\n",
    "\n",
    "#reordenando as colunas ...\n",
    "final_result = final_result[['ITE_ITEM_TITLE_PROCURADO' , 'ITE_ITEM_TITLE_CATALOGO' , 'SIMILARIDADE']] \n",
    "final_result = final_result.reset_index(drop=True)\n",
    "\n",
    "\n",
    "final_result.to_excel( \"resultado.xlsx\",sheet_name='Similaridade') \n",
    "\n",
    "print('Informações sobre o tempo de execução das predições')\n",
    "print(avaliacao_performance_predicao['Tempo'].describe())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
